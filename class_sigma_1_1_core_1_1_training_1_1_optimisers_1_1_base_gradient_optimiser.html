<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Sigma: Sigma.Core.Training.Optimisers.BaseGradientOptimiser Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="128x128.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Sigma
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespace_sigma.html">Sigma</a></li><li class="navelem"><a class="el" href="namespace_sigma_1_1_core.html">Core</a></li><li class="navelem"><a class="el" href="namespace_sigma_1_1_core_1_1_training.html">Training</a></li><li class="navelem"><a class="el" href="namespace_sigma_1_1_core_1_1_training_1_1_optimisers.html">Optimisers</a></li><li class="navelem"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html">BaseGradientOptimiser</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="#properties">Properties</a> &#124;
<a href="#pri-attribs">Private Attributes</a> &#124;
<a href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">Sigma.Core.Training.Optimisers.BaseGradientOptimiser Class Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p>A base class for gradient based optimisers for easier implementation (all parameters treated as ndarray and passed with identifiers). Provides a default implementation of the cost calculation algorithm.  
 <a href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for Sigma.Core.Training.Optimisers.BaseGradientOptimiser:</div>
<div class="dyncontent">
 <div class="center">
  <img src="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.png" usemap="#Sigma.Core.Training.Optimisers.BaseGradientOptimiser_map" alt=""/>
  <map id="Sigma.Core.Training.Optimisers.BaseGradientOptimiser_map" name="Sigma.Core.Training.Optimisers.BaseGradientOptimiser_map">
<area href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html" title="An optimiser that defines how a network (model) should be optimised by implementing a single iteratio..." alt="Sigma.Core.Training.Optimisers.IOptimiser" shape="rect" coords="0,56,342,80"/>
<area href="interface_sigma_1_1_core_1_1_utils_1_1_i_deep_copyable.html" title="A deep copyable object. &quot;Deep&quot; means all child references are recursively copied down to actual copya..." alt="Sigma.Core.Utils.IDeepCopyable" shape="rect" coords="0,0,342,24"/>
<area href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_gradient_descent_optimiser.html" title="A gradient descent optimiser, using the gradient descent algorithm with a certain learning rate on ea..." alt="Sigma.Core.Training.Optimisers.GradientDescentOptimiser" shape="rect" coords="0,168,342,192"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a887dbc786619ff639188c263ea53eeb0"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a887dbc786619ff639188c263ea53eeb0">PrepareRun</a> (<a class="el" href="interface_sigma_1_1_core_1_1_architecture_1_1_i_network.html">INetwork</a> network, <a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a> handler)</td></tr>
<tr class="memdesc:a887dbc786619ff639188c263ea53eeb0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prepare for a single iteration of the network (model) optimisation process (<a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a0e45ba9c56c6decddab483b3ca6a80bc" title="Run a single iteration of the network (model) optimisation process (e.g. backward pass only)...">IOptimiser.Run</a>). Typically used to trace trainable parameters to retrieve the derivatives in <a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a0e45ba9c56c6decddab483b3ca6a80bc" title="Run a single iteration of the network (model) optimisation process (e.g. backward pass only)...">IOptimiser.Run</a>.  <a href="#a887dbc786619ff639188c263ea53eeb0">More...</a><br /></td></tr>
<tr class="separator:a887dbc786619ff639188c263ea53eeb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7df3e72c50c71ce542682a7788aee686"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a7df3e72c50c71ce542682a7788aee686">Run</a> (<a class="el" href="interface_sigma_1_1_core_1_1_architecture_1_1_i_network.html">INetwork</a> network, <a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a> handler)</td></tr>
<tr class="memdesc:a7df3e72c50c71ce542682a7788aee686"><td class="mdescLeft">&#160;</td><td class="mdescRight">Run a single iteration of the network (model) optimisation process (e.g. backward pass only). Note: The gradients are typically used to update the parameters in a certain way to optimise the network.  <a href="#a7df3e72c50c71ce542682a7788aee686">More...</a><br /></td></tr>
<tr class="separator:a7df3e72c50c71ce542682a7788aee686"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a54023d1e32e383919cb7339c85899487"><td class="memItemLeft" align="right" valign="top">abstract object&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a54023d1e32e383919cb7339c85899487">DeepCopy</a> ()</td></tr>
<tr class="memdesc:a54023d1e32e383919cb7339c85899487"><td class="mdescLeft">&#160;</td><td class="mdescRight">Deep copy this object.  <a href="#a54023d1e32e383919cb7339c85899487">More...</a><br /></td></tr>
<tr class="separator:a54023d1e32e383919cb7339c85899487"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:a9d7ddddffb8617f9f476770d535e1228"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a9d7ddddffb8617f9f476770d535e1228">BaseGradientOptimiser</a> (string externalCostAlias=&quot;external_cost&quot;)</td></tr>
<tr class="memdesc:a9d7ddddffb8617f9f476770d535e1228"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a base gradient optimiser with an optional external output cost alias to use.  <a href="#a9d7ddddffb8617f9f476770d535e1228">More...</a><br /></td></tr>
<tr class="separator:a9d7ddddffb8617f9f476770d535e1228"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad449a1302c42c3c675b3644d6a9af813"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_number.html">INumber</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#ad449a1302c42c3c675b3644d6a9af813">GetTotalCost</a> (<a class="el" href="interface_sigma_1_1_core_1_1_architecture_1_1_i_network.html">INetwork</a> network, <a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a> handler, <a class="el" href="interface_sigma_1_1_core_1_1_utils_1_1_i_registry.html">IRegistry</a> costRegistry)</td></tr>
<tr class="memdesc:ad449a1302c42c3c675b3644d6a9af813"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the total cost from a certain network using a certain computation handler and put the relevant information in the cost registry (total, partial, importances).  <a href="#ad449a1302c42c3c675b3644d6a9af813">More...</a><br /></td></tr>
<tr class="separator:ad449a1302c42c3c675b3644d6a9af813"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d45ed05f9c0dadb66e924a1425542e9"><td class="memItemLeft" align="right" valign="top">abstract <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a7d45ed05f9c0dadb66e924a1425542e9">Optimise</a> (string paramIdentifier, <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a> parameter, <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a> gradient, <a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a> handler)</td></tr>
<tr class="memdesc:a7d45ed05f9c0dadb66e924a1425542e9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Optimise a certain parameter given a certain gradient using a certain computation handler.  <a href="#a7d45ed05f9c0dadb66e924a1425542e9">More...</a><br /></td></tr>
<tr class="separator:a7d45ed05f9c0dadb66e924a1425542e9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a3891206c6eb940a572975c852c48ae88"><td class="memItemLeft" align="right" valign="top"><a id="a3891206c6eb940a572975c852c48ae88"></a>
readonly string&#160;</td><td class="memItemRight" valign="bottom"><b>ExternalCostAlias</b></td></tr>
<tr class="separator:a3891206c6eb940a572975c852c48ae88"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="properties"></a>
Properties</h2></td></tr>
<tr class="memitem:a9486d8f5cf58962bfb54309d9bed595e"><td class="memItemLeft" align="right" valign="top"><a class="el" href="interface_sigma_1_1_core_1_1_utils_1_1_i_registry.html">IRegistry</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a9486d8f5cf58962bfb54309d9bed595e">Registry</a><code> [get]</code></td></tr>
<tr class="memdesc:a9486d8f5cf58962bfb54309d9bed595e"><td class="mdescLeft">&#160;</td><td class="mdescRight">The registry containing data about this optimiser and its last run.  <a href="#a9486d8f5cf58962bfb54309d9bed595e">More...</a><br /></td></tr>
<tr class="separator:a9486d8f5cf58962bfb54309d9bed595e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header properties_interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser"><td colspan="2" onclick="javascript:toggleInherit('properties_interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser')"><img src="closed.png" alt="-"/>&#160;Properties inherited from <a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html">Sigma.Core.Training.Optimisers.IOptimiser</a></td></tr>
<tr class="memitem:a9fa7059c11931d486e16aa9a7b5c1b0c inherit properties_interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser"><td class="memItemLeft" align="right" valign="top"><a class="el" href="interface_sigma_1_1_core_1_1_utils_1_1_i_registry.html">IRegistry</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a9fa7059c11931d486e16aa9a7b5c1b0c">Registry</a><code> [get]</code></td></tr>
<tr class="memdesc:a9fa7059c11931d486e16aa9a7b5c1b0c inherit properties_interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser"><td class="mdescLeft">&#160;</td><td class="mdescRight">The registry containing data about this optimiser and its last run.  <a href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a9fa7059c11931d486e16aa9a7b5c1b0c">More...</a><br /></td></tr>
<tr class="separator:a9fa7059c11931d486e16aa9a7b5c1b0c inherit properties_interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pri-attribs"></a>
Private Attributes</h2></td></tr>
<tr class="memitem:a4c7bf9962e0959190ae131c9173a7654"><td class="memItemLeft" align="right" valign="top"><a id="a4c7bf9962e0959190ae131c9173a7654"></a>
readonly ILog&#160;</td><td class="memItemRight" valign="bottom"><b>_logger</b> = LogManager.GetLogger(System.Reflection.MethodBase.GetCurrentMethod().DeclaringType)</td></tr>
<tr class="separator:a4c7bf9962e0959190ae131c9173a7654"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a392945cbef369dd8d7c470f2a0ca8e92"><td class="memItemLeft" align="right" valign="top"><a id="a392945cbef369dd8d7c470f2a0ca8e92"></a>
bool&#160;</td><td class="memItemRight" valign="bottom"><b>_prepared</b></td></tr>
<tr class="separator:a392945cbef369dd8d7c470f2a0ca8e92"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2f0385957459a97a9cf7ef5fa073e1f"><td class="memItemLeft" align="right" valign="top"><a id="ab2f0385957459a97a9cf7ef5fa073e1f"></a>
uint&#160;</td><td class="memItemRight" valign="bottom"><b>_traceTag</b></td></tr>
<tr class="separator:ab2f0385957459a97a9cf7ef5fa073e1f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>A base class for gradient based optimisers for easier implementation (all parameters treated as ndarray and passed with identifiers). Provides a default implementation of the cost calculation algorithm. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a9d7ddddffb8617f9f476770d535e1228"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9d7ddddffb8617f9f476770d535e1228">&#9670;&nbsp;</a></span>BaseGradientOptimiser()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Sigma.Core.Training.Optimisers.BaseGradientOptimiser.BaseGradientOptimiser </td>
          <td>(</td>
          <td class="paramtype">string&#160;</td>
          <td class="paramname"><em>externalCostAlias</em> = <code>&quot;external_cost&quot;</code></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Create a base gradient optimiser with an optional external output cost alias to use. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">externalCostAlias</td><td>The optional external output identifier by which to detect cost layers (defaults to "external_cost").</td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a54023d1e32e383919cb7339c85899487"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a54023d1e32e383919cb7339c85899487">&#9670;&nbsp;</a></span>DeepCopy()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">abstract object Sigma.Core.Training.Optimisers.BaseGradientOptimiser.DeepCopy </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Deep copy this object. </p>
<dl class="section return"><dt>Returns</dt><dd>A deep copy of this object.</dd></dl>

<p>Implements <a class="el" href="interface_sigma_1_1_core_1_1_utils_1_1_i_deep_copyable.html#ab066dde4b00126e9c9b39764887b22b1">Sigma.Core.Utils.IDeepCopyable</a>.</p>

<p>Implemented in <a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_gradient_descent_optimiser.html#aa5ccc55bab82af462a6e64c6ec9b034f">Sigma.Core.Training.Optimisers.GradientDescentOptimiser</a>.</p>

</div>
</div>
<a id="ad449a1302c42c3c675b3644d6a9af813"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad449a1302c42c3c675b3644d6a9af813">&#9670;&nbsp;</a></span>GetTotalCost()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_number.html">INumber</a> Sigma.Core.Training.Optimisers.BaseGradientOptimiser.GetTotalCost </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_architecture_1_1_i_network.html">INetwork</a>&#160;</td>
          <td class="paramname"><em>network</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a>&#160;</td>
          <td class="paramname"><em>handler</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_utils_1_1_i_registry.html">IRegistry</a>&#160;</td>
          <td class="paramname"><em>costRegistry</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the total cost from a certain network using a certain computation handler and put the relevant information in the cost registry (total, partial, importances). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">network</td><td>The network to get the costs from.</td></tr>
    <tr><td class="paramname">handler</td><td>The handler to use.</td></tr>
    <tr><td class="paramname">costRegistry</td><td>The registry to put relevant information in.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The total cost of the given network (0.0 if none).</dd></dl>

</div>
</div>
<a id="a7d45ed05f9c0dadb66e924a1425542e9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7d45ed05f9c0dadb66e924a1425542e9">&#9670;&nbsp;</a></span>Optimise()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">abstract <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a> Sigma.Core.Training.Optimisers.BaseGradientOptimiser.Optimise </td>
          <td>(</td>
          <td class="paramtype">string&#160;</td>
          <td class="paramname"><em>paramIdentifier</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a>&#160;</td>
          <td class="paramname"><em>parameter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a>&#160;</td>
          <td class="paramname"><em>gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a>&#160;</td>
          <td class="paramname"><em>handler</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Optimise a certain parameter given a certain gradient using a certain computation handler. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">paramIdentifier</td><td>The parameter identifier (e.g. "3-elementwise.weights").</td></tr>
    <tr><td class="paramname">parameter</td><td>The parameter to optimise.</td></tr>
    <tr><td class="paramname">gradient</td><td>The gradient of the parameter respective to the total cost.</td></tr>
    <tr><td class="paramname">handler</td><td>The handler to use.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd></dd></dl>

<p>Implemented in <a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_gradient_descent_optimiser.html#ac49e657bd17d180f4766c5b653d7ff73">Sigma.Core.Training.Optimisers.GradientDescentOptimiser</a>.</p>

</div>
</div>
<a id="a887dbc786619ff639188c263ea53eeb0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a887dbc786619ff639188c263ea53eeb0">&#9670;&nbsp;</a></span>PrepareRun()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Sigma.Core.Training.Optimisers.BaseGradientOptimiser.PrepareRun </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_architecture_1_1_i_network.html">INetwork</a>&#160;</td>
          <td class="paramname"><em>network</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a>&#160;</td>
          <td class="paramname"><em>handler</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Prepare for a single iteration of the network (model) optimisation process (<a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a0e45ba9c56c6decddab483b3ca6a80bc" title="Run a single iteration of the network (model) optimisation process (e.g. backward pass only)...">IOptimiser.Run</a>). Typically used to trace trainable parameters to retrieve the derivatives in <a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a0e45ba9c56c6decddab483b3ca6a80bc" title="Run a single iteration of the network (model) optimisation process (e.g. backward pass only)...">IOptimiser.Run</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">network</td><td>The network to prepare for optimisation.</td></tr>
    <tr><td class="paramname">handler</td><td>THe handler to use.</td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a9e58c71aba7c2a3558096a187ceda545">Sigma.Core.Training.Optimisers.IOptimiser</a>.</p>

</div>
</div>
<a id="a7df3e72c50c71ce542682a7788aee686"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7df3e72c50c71ce542682a7788aee686">&#9670;&nbsp;</a></span>Run()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void Sigma.Core.Training.Optimisers.BaseGradientOptimiser.Run </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_architecture_1_1_i_network.html">INetwork</a>&#160;</td>
          <td class="paramname"><em>network</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a>&#160;</td>
          <td class="paramname"><em>handler</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Run a single iteration of the network (model) optimisation process (e.g. backward pass only). Note: The gradients are typically used to update the parameters in a certain way to optimise the network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">network</td><td>The network to optimise.</td></tr>
    <tr><td class="paramname">handler</td><td>The computation handler to use.</td></tr>
  </table>
  </dd>
</dl>

<p>Implements <a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a0e45ba9c56c6decddab483b3ca6a80bc">Sigma.Core.Training.Optimisers.IOptimiser</a>.</p>

</div>
</div>
<h2 class="groupheader">Property Documentation</h2>
<a id="a9486d8f5cf58962bfb54309d9bed595e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9486d8f5cf58962bfb54309d9bed595e">&#9670;&nbsp;</a></span>Registry</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="interface_sigma_1_1_core_1_1_utils_1_1_i_registry.html">IRegistry</a> Sigma.Core.Training.Optimisers.BaseGradientOptimiser.Registry</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">get</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>The registry containing data about this optimiser and its last run. </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>C:/Users/Plainer/Documents/GitHub/Sigma/Sigma.Core/Training/Optimisers/BaseGradientOptimiser.cs</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
