<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Sigma: Sigma.Core.Training.Optimisers.GradientDescentOptimiser Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="128x128.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Sigma
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespace_sigma.html">Sigma</a></li><li class="navelem"><a class="el" href="namespace_sigma_1_1_core.html">Core</a></li><li class="navelem"><a class="el" href="namespace_sigma_1_1_core_1_1_training.html">Training</a></li><li class="navelem"><a class="el" href="namespace_sigma_1_1_core_1_1_training_1_1_optimisers.html">Optimisers</a></li><li class="navelem"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_gradient_descent_optimiser.html">GradientDescentOptimiser</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_gradient_descent_optimiser-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">Sigma.Core.Training.Optimisers.GradientDescentOptimiser Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>A gradient descent optimiser, using the gradient descent algorithm with a certain learning rate on each parameter.  
 <a href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_gradient_descent_optimiser.html#details">More...</a></p>
<div class="dynheader">
Inheritance diagram for Sigma.Core.Training.Optimisers.GradientDescentOptimiser:</div>
<div class="dyncontent">
 <div class="center">
  <img src="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_gradient_descent_optimiser.png" usemap="#Sigma.Core.Training.Optimisers.GradientDescentOptimiser_map" alt=""/>
  <map id="Sigma.Core.Training.Optimisers.GradientDescentOptimiser_map" name="Sigma.Core.Training.Optimisers.GradientDescentOptimiser_map">
<area href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html" title="A base class for gradient based optimisers for easier implementation (all parameters treated as ndarr..." alt="Sigma.Core.Training.Optimisers.BaseGradientOptimiser" shape="rect" coords="0,112,342,136"/>
<area href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html" title="An optimiser that defines how a network (model) should be optimised by implementing a single iteratio..." alt="Sigma.Core.Training.Optimisers.IOptimiser" shape="rect" coords="0,56,342,80"/>
<area href="interface_sigma_1_1_core_1_1_utils_1_1_i_deep_copyable.html" title="A deep copyable object. &quot;Deep&quot; means all child references are recursively copied down to actual copya..." alt="Sigma.Core.Utils.IDeepCopyable" shape="rect" coords="0,0,342,24"/>
</map>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ab019bf65bc92e14c28f07a212f83e44d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_gradient_descent_optimiser.html#ab019bf65bc92e14c28f07a212f83e44d">GradientDescentOptimiser</a> (double learningRate, string externalCostAlias=&quot;external_cost&quot;)</td></tr>
<tr class="memdesc:ab019bf65bc92e14c28f07a212f83e44d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a gradient descent optimiser with a certain learning rate.  <a href="#ab019bf65bc92e14c28f07a212f83e44d">More...</a><br /></td></tr>
<tr class="separator:ab019bf65bc92e14c28f07a212f83e44d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa5ccc55bab82af462a6e64c6ec9b034f"><td class="memItemLeft" align="right" valign="top">override object&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_gradient_descent_optimiser.html#aa5ccc55bab82af462a6e64c6ec9b034f">DeepCopy</a> ()</td></tr>
<tr class="memdesc:aa5ccc55bab82af462a6e64c6ec9b034f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Deep copy this object.  <a href="#aa5ccc55bab82af462a6e64c6ec9b034f">More...</a><br /></td></tr>
<tr class="separator:aa5ccc55bab82af462a6e64c6ec9b034f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html">Sigma.Core.Training.Optimisers.BaseGradientOptimiser</a></td></tr>
<tr class="memitem:a887dbc786619ff639188c263ea53eeb0 inherit pub_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a887dbc786619ff639188c263ea53eeb0">PrepareRun</a> (<a class="el" href="interface_sigma_1_1_core_1_1_architecture_1_1_i_network.html">INetwork</a> network, <a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a> handler)</td></tr>
<tr class="memdesc:a887dbc786619ff639188c263ea53eeb0 inherit pub_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="mdescLeft">&#160;</td><td class="mdescRight">Prepare for a single iteration of the network (model) optimisation process (<a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a0e45ba9c56c6decddab483b3ca6a80bc" title="Run a single iteration of the network (model) optimisation process (e.g. backward pass only)...">IOptimiser.Run</a>). Typically used to trace trainable parameters to retrieve the derivatives in <a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a0e45ba9c56c6decddab483b3ca6a80bc" title="Run a single iteration of the network (model) optimisation process (e.g. backward pass only)...">IOptimiser.Run</a>.  <a href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a887dbc786619ff639188c263ea53eeb0">More...</a><br /></td></tr>
<tr class="separator:a887dbc786619ff639188c263ea53eeb0 inherit pub_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7df3e72c50c71ce542682a7788aee686 inherit pub_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a7df3e72c50c71ce542682a7788aee686">Run</a> (<a class="el" href="interface_sigma_1_1_core_1_1_architecture_1_1_i_network.html">INetwork</a> network, <a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a> handler)</td></tr>
<tr class="memdesc:a7df3e72c50c71ce542682a7788aee686 inherit pub_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="mdescLeft">&#160;</td><td class="mdescRight">Run a single iteration of the network (model) optimisation process (e.g. backward pass only). Note: The gradients are typically used to update the parameters in a certain way to optimise the network.  <a href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a7df3e72c50c71ce542682a7788aee686">More...</a><br /></td></tr>
<tr class="separator:a7df3e72c50c71ce542682a7788aee686 inherit pub_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:ac49e657bd17d180f4766c5b653d7ff73"><td class="memItemLeft" align="right" valign="top">override <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_gradient_descent_optimiser.html#ac49e657bd17d180f4766c5b653d7ff73">Optimise</a> (string paramIdentifier, <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a> parameter, <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a> gradient, <a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a> handler)</td></tr>
<tr class="memdesc:ac49e657bd17d180f4766c5b653d7ff73"><td class="mdescLeft">&#160;</td><td class="mdescRight">Optimise a certain parameter given a certain gradient using a certain computation handler.  <a href="#ac49e657bd17d180f4766c5b653d7ff73">More...</a><br /></td></tr>
<tr class="separator:ac49e657bd17d180f4766c5b653d7ff73"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pro_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td colspan="2" onclick="javascript:toggleInherit('pro_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser')"><img src="closed.png" alt="-"/>&#160;Protected Member Functions inherited from <a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html">Sigma.Core.Training.Optimisers.BaseGradientOptimiser</a></td></tr>
<tr class="memitem:a9d7ddddffb8617f9f476770d535e1228 inherit pro_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a9d7ddddffb8617f9f476770d535e1228">BaseGradientOptimiser</a> (string externalCostAlias=&quot;external_cost&quot;)</td></tr>
<tr class="memdesc:a9d7ddddffb8617f9f476770d535e1228 inherit pro_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a base gradient optimiser with an optional external output cost alias to use.  <a href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a9d7ddddffb8617f9f476770d535e1228">More...</a><br /></td></tr>
<tr class="separator:a9d7ddddffb8617f9f476770d535e1228 inherit pro_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad449a1302c42c3c675b3644d6a9af813 inherit pro_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memItemLeft" align="right" valign="top">virtual <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_number.html">INumber</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#ad449a1302c42c3c675b3644d6a9af813">GetTotalCost</a> (<a class="el" href="interface_sigma_1_1_core_1_1_architecture_1_1_i_network.html">INetwork</a> network, <a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a> handler, <a class="el" href="interface_sigma_1_1_core_1_1_utils_1_1_i_registry.html">IRegistry</a> costRegistry)</td></tr>
<tr class="memdesc:ad449a1302c42c3c675b3644d6a9af813 inherit pro_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the total cost from a certain network using a certain computation handler and put the relevant information in the cost registry (total, partial, importances).  <a href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#ad449a1302c42c3c675b3644d6a9af813">More...</a><br /></td></tr>
<tr class="separator:ad449a1302c42c3c675b3644d6a9af813 inherit pro_methods_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="inherited"></a>
Additional Inherited Members</h2></td></tr>
<tr class="inherit_header pro_attribs_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td colspan="2" onclick="javascript:toggleInherit('pro_attribs_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser')"><img src="closed.png" alt="-"/>&#160;Protected Attributes inherited from <a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html">Sigma.Core.Training.Optimisers.BaseGradientOptimiser</a></td></tr>
<tr class="memitem:a3891206c6eb940a572975c852c48ae88 inherit pro_attribs_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memItemLeft" align="right" valign="top"><a id="a3891206c6eb940a572975c852c48ae88"></a>
readonly string&#160;</td><td class="memItemRight" valign="bottom"><b>ExternalCostAlias</b></td></tr>
<tr class="separator:a3891206c6eb940a572975c852c48ae88 inherit pro_attribs_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header properties_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td colspan="2" onclick="javascript:toggleInherit('properties_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser')"><img src="closed.png" alt="-"/>&#160;Properties inherited from <a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html">Sigma.Core.Training.Optimisers.BaseGradientOptimiser</a></td></tr>
<tr class="memitem:a9486d8f5cf58962bfb54309d9bed595e inherit properties_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memItemLeft" align="right" valign="top"><a class="el" href="interface_sigma_1_1_core_1_1_utils_1_1_i_registry.html">IRegistry</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a9486d8f5cf58962bfb54309d9bed595e">Registry</a><code> [get]</code></td></tr>
<tr class="memdesc:a9486d8f5cf58962bfb54309d9bed595e inherit properties_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="mdescLeft">&#160;</td><td class="mdescRight">The registry containing data about this optimiser and its last run.  <a href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a9486d8f5cf58962bfb54309d9bed595e">More...</a><br /></td></tr>
<tr class="separator:a9486d8f5cf58962bfb54309d9bed595e inherit properties_class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header properties_interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser"><td colspan="2" onclick="javascript:toggleInherit('properties_interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser')"><img src="closed.png" alt="-"/>&#160;Properties inherited from <a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html">Sigma.Core.Training.Optimisers.IOptimiser</a></td></tr>
<tr class="memitem:a9fa7059c11931d486e16aa9a7b5c1b0c inherit properties_interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser"><td class="memItemLeft" align="right" valign="top"><a class="el" href="interface_sigma_1_1_core_1_1_utils_1_1_i_registry.html">IRegistry</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a9fa7059c11931d486e16aa9a7b5c1b0c">Registry</a><code> [get]</code></td></tr>
<tr class="memdesc:a9fa7059c11931d486e16aa9a7b5c1b0c inherit properties_interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser"><td class="mdescLeft">&#160;</td><td class="mdescRight">The registry containing data about this optimiser and its last run.  <a href="interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser.html#a9fa7059c11931d486e16aa9a7b5c1b0c">More...</a><br /></td></tr>
<tr class="separator:a9fa7059c11931d486e16aa9a7b5c1b0c inherit properties_interface_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_i_optimiser"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>A gradient descent optimiser, using the gradient descent algorithm with a certain learning rate on each parameter. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="ab019bf65bc92e14c28f07a212f83e44d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab019bf65bc92e14c28f07a212f83e44d">&#9670;&nbsp;</a></span>GradientDescentOptimiser()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">Sigma.Core.Training.Optimisers.GradientDescentOptimiser.GradientDescentOptimiser </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>learningRate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">string&#160;</td>
          <td class="paramname"><em>externalCostAlias</em> = <code>&quot;external_cost&quot;</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a gradient descent optimiser with a certain learning rate. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">learningRate</td><td>The learning rate.</td></tr>
    <tr><td class="paramname">externalCostAlias</td><td>The optional external output identifier by which to detect cost layers (defaults to "external_cost").</td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="aa5ccc55bab82af462a6e64c6ec9b034f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa5ccc55bab82af462a6e64c6ec9b034f">&#9670;&nbsp;</a></span>DeepCopy()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">override object Sigma.Core.Training.Optimisers.GradientDescentOptimiser.DeepCopy </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Deep copy this object. </p>
<dl class="section return"><dt>Returns</dt><dd>A deep copy of this object.</dd></dl>

<p>Implements <a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a54023d1e32e383919cb7339c85899487">Sigma.Core.Training.Optimisers.BaseGradientOptimiser</a>.</p>

</div>
</div>
<a id="ac49e657bd17d180f4766c5b653d7ff73"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac49e657bd17d180f4766c5b653d7ff73">&#9670;&nbsp;</a></span>Optimise()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">override <a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a> Sigma.Core.Training.Optimisers.GradientDescentOptimiser.Optimise </td>
          <td>(</td>
          <td class="paramtype">string&#160;</td>
          <td class="paramname"><em>paramIdentifier</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a>&#160;</td>
          <td class="paramname"><em>parameter</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_math_abstract_1_1_i_n_d_array.html">INDArray</a>&#160;</td>
          <td class="paramname"><em>gradient</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="interface_sigma_1_1_core_1_1_handlers_1_1_i_computation_handler.html">IComputationHandler</a>&#160;</td>
          <td class="paramname"><em>handler</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Optimise a certain parameter given a certain gradient using a certain computation handler. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">paramIdentifier</td><td>The parameter identifier (e.g. "3-elementwise.weights").</td></tr>
    <tr><td class="paramname">parameter</td><td>The parameter to optimise.</td></tr>
    <tr><td class="paramname">gradient</td><td>The gradient of the parameter respective to the total cost.</td></tr>
    <tr><td class="paramname">handler</td><td>The handler to use.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd></dd></dl>

<p>Implements <a class="el" href="class_sigma_1_1_core_1_1_training_1_1_optimisers_1_1_base_gradient_optimiser.html#a7d45ed05f9c0dadb66e924a1425542e9">Sigma.Core.Training.Optimisers.BaseGradientOptimiser</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>C:/Users/Plainer/Documents/GitHub/Sigma/Sigma.Core/Training/Optimisers/GradientDescentOptimiser.cs</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
